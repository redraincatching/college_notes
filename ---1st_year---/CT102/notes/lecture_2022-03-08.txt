merge sort - a recursive sorting algorithm
    an approach to sorting that involves dividing the sorting problem into smaller and smaller sub-problems, sorting those, and then merging those sorted problems back together
    developed in 1945 by jon von neumann

    approach:
        - instead of the full array, consider two subarrays with size as equal as possible
        - keep considering subarrays until size 1 reached
        - for each subarray, in sorted order, merge back with next, in sorted order

    input:
        - array arr_a[] of size size, in unsorted order
        - lower bound lb, initially 0
        - upper bound ub, initially size-1

    output:
        - array arr_a[] of size size, in ascending sorted order

    steps:
        1) dividing:
            continuously reduce array and subarrays until size 1 reached (trivially in sorted order)
        2) merging:
            continuously merge back into sorted order

        step 1:
            [diagram]
            splitting each at mid until size 1 reached

        step 2:
            [diagram]
            merge each back into order

    c code:
        void merge_sort (int arr_a[], int lb, int ub) {
            int mid;

            if (lb < ub) {
                mid = int((lb + ub) /2);
                merge_sort (arr_a, lb, mid);        // split array into upper and lower half
                merge_sort (arr_a, mid + 1, ub);
                merge (arr_a, lb, mid, ub);         // once recursive calls have finished, merge
           }
        }

        // note that while the merge_sort function is recursive, merge is iterative

        void merge (int arr_a[], int lb, int mid, int ub) {

              int i, j, k;
        	  int size = ub - lb + 1;
        	  int *arr_c;
        	  //create arr_c[] to be of size needed for current merge
        	  arr_c = (int*) malloc(size * sizeof(int));

        	  i = lb;
        	  j = mid + 1;
        	  k = 0;

        	  while (i <= mid && j <= ub) {
        		if(arr_a[i] <= arr_a[j]) {
        			arr_c[k] = arr_a[i];
        			i++;
        		}
        		else {
        			arr_c[k] = arr_a[j];
        			j++;
        		}
        		k++;
        	} //end while

        	// write out anything left in i part
        	while (i <= mid) {
        		arr_c[k] = arr_a[i];
        		i++;
        		k++;
        	}
        	// write out anything left in j part
        	while (j <= ub) {
        		arr_c[k] = arr_a[j];
        		j++;
        		k++;
        	}

        	//write back from arr_c to arr_a so correct values are in place for next merge
        	i = lb;
        	k = 0;
        	while ( i <= ub ) {
        		arr_a[i] = arr_c[k];
        		i++;
        		k++;
        	}
        }

        time complexity of these?
            [bunch of diagrams]
            - this merge function takes 17n + 20 steps every time it executes
            - mergesort take a function of (n/2)
            the whole function would be a function of n, so we can write
                f(n) = 2f(n/2) + 17n + 23
            // writing 17 as a constant c, and 23 as a constant cn
                in general,
                    f(n) = 2^k f(n/2^k) + k cn + const
            [solve for k diagrams]

            complexity - O(n log_2 n)

            notes:
                - best and worst case are similar
                - fewer comparisons than quicksort
                - general purpose sorting technique, unlike countsort
                - does not sort in place. requires an array of equal size for temporary holding and a writeback stage. good time complexity, but poor space complexity
