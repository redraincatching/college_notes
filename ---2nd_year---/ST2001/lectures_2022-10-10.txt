some discrete probability distributions
    motivation
        often, the observations generated by statistical experiments have the same type of behaviour

    binary outcomes
        bernoulli trial
            random experiment with two outcomes
            for a single trial, random variable X = 1 if success, 0 if failure
            where P(X=1) = p and P(X=0) = 1-p
                or
            P(X=x)=p^x(1-p)^(1-x)  x = (0,1)

            mean:
                E[X] = (0)(1-p) + (1)p = p
                expected value is n*p
            variance:
                Var(X) = E(X^2) - E(X)^2

            outcomes of trials must be independent
            probability of success p must be constant over trials

        binomial distribution
            a random experiment consists of n bernoulli trials such that
                1) the trials are independent
                2) each trial has only two outcomes, success and failure
                3) success probability, p, stays constant

            the random variable X that equal the number of trials that result in a success has a binomial random variable with parameters 0 < p < 1
            the probability mass function is
                f(x) = (nCx)p^x(1-p)^(n-x)  x = 0, 1, 2, ..., n

            r command
                dbinom(x, size, prob)
                    x is events of interest
                    size is total nmber of trials
                    prob is probability of x

            // also see artofstat.com

    chebyshev's inequality
        at least 75% of values lie within two standard deviations of the mean