programs and processes
    program
        a static entity made up of source code statements which define the behaviour fo a process
    process
        a dynamic entity that executes a programon a particular set of data using resources allocated by the system
        -> multiple processes can execute the same program

    a process is a program in execution
    composed of 
        - program
        - data
        - process control block, containing the state of the process

    execution of a process
        a process needs an abstract mabhine environment in order to execute, to manage its use on resources
        the process control block is required to map the environment state onto the physical machine state
        the os keeps a process descriptor for each process
        [[diagram]]
            -> this is all so the process does not need to constantly request the os for resources

    execution of a program
        each execution of a program generates a process that is executed
        inter-process relationships
            - competition: processes are trying to access different parts of the system, therefore protection is necessary
            - cooperation: sometimes the processes need to communicate between themselves in order to synchronise correctly

        process manager functions
            implements: 
                cpu sharing: 
                    called scheduling, allocates resources in accordance with certain policies
                process synchronisation and inter-process communication:
                    deadlock strategies and protection mechanisms
                [[diagram]]
    
processes from different perspectives
    user perspective
        consider an application that monitors an industrial process, and records its operation
        the application contains 4 program modules
            - data acquisition (collect): 
                reads 3 values from a converter
                each collection is 1 time interval (1t), 1/4t processor, 3/4t waiting for read op to finish
                    // cpu is always the fastest thing in a computer, so it spends a lot of time waiting
            - data storage (log)
                writes the 3 collected values onto the disk
                neads two operations: write 2 chars at a time, including '\n'
                1/2t processor time, 3/2t waiting for write to finish
            - statistical processing (stat)
                statistical processing of values
                2t processor time
            - print results (report)
                prints two vaues from stat
                each print needs 1/4t processor time, 5/4t waiting for print to finish

        sequential implementation
            main() {
                while (TRUE) {
                    collect();
                    log();
                    stat();
                    report();
                }
            }

            [[diagram]]

            time required for a cycle is 12t
                4.25t processor time
                7.75t waiting for various i/o operations

        multitasking implementaion
            while the cpu is waiting, use that time to work on other tasks
            however; some programs depend on each other to run

            we'll execute the processes in quasi-parallel, so that the programs can tlak to each other, using the following priority order
                - log
                - collect
                - report
                - stat
            
            we need some synchronicity, this can be done using the wait and signal directives
                wait: wait for a signal from a specific process
                signal: signal another process to start

                e.g. 
                    void log(){
                        while(TRUE){
                            wait(collect);  // log needs to wait for collect to find data to log
                            log_disk();
                            signal (collect);
                        }
                    }
                    void collect(){
                        while(TRUE){
                            wait (log);     // can't add more data if it's not logged
                            wait (stat);    
                            collect_ad();
                            signal (log);   // tell log to start
                            signal (stat);  // stat can start to run
                        }
                    }
                    void report(){
                        while (TRUE){
                            wait (stat);    // wait for stats to be reported
                            report_pr ();
                            signal (stat);
                        }
                    }
                    void stat(){
                        while (TRUE){
                            wait (collect);
                            wait (report);
                            stat_ad ();
                            signal (collect);
                            signal (report)
                        }
                    }

                    main(){
                        init_proc(&log(), …);
                        init_proc(&collect(), …);
                        init_proc(&report(), …);
                        init_proc(&stat(),…);

                        signal (collect); signal (collect);
                        signal (stat);
                        start_schedule();
                    }

                [[diagram]]
                    - 5.25t execution time
                    - only 1t lost waiting for i/o operations

            the main challenge of synchronicity is modelling these cooperations and dependencies
        
        from the user perspective, however, the important part is that the porgram runs as fast as possible
    
    os perspective
        the processor's principal function: execute machine instructions residing in main memory
            - those instructions are provided in the form of programs
            - a processor may interleave the execution of multiple programs at a time

        program view
            its execution involves a sequence of instructions in the program
            the behaviour of individual processes can be characterised by a sequence of instructions
                -> the _trace_ of a process
                    every process will follow the steps of their trace in order, and the os cannot change this
                // recall context switching - if the os switches which program is being executed, it won't notice
            
        processor view
            executes code as dictated by changing values in the pc register
            the behaviour of the processor can be characterised by showing how the traces of various processes are interleaved

state process models
    [[diagram]]
    // note: a computer can have as many processes running at one time as it has cores
    // the five-state model is generally what computers use today

    two-state model
        the process can be in one of two states, running or not running
        when a process is created, it is known to the os and enters the not running state
        from time to time, the currently running process is interrupted and the dispatcher selects the next process to run from the queue

        process creation
            - the os builds the data structures that are used to manage the process
            - the os allocates space in main memory for the process

            reasons for process creation
                - new batch job
                - created by os to control a service, e.g. printing
                - spawned by existing process, as child or to exploit paallelism

        process termination
            reasons
                - process has finished execution
                - total time limit exceeded
                - errors
                - parent request
                - parent has terminated - e.g. terminal opening programs in linux

        queueing discipline
            each process needs to be represented
                - info relating to each process, including current state and memory location
                - waiting processes are kept in a queue
                    - list of pointers to data blocks, or linked list
            dispatcher behaviour
                - an interrupted process is transferred in the waiting queue
                    -> if process is completed or aborted, it is discarded
                - the dispatcher selects a process to execute
                [[diagram]]
                simple, yet inefficient, as some processes may still be waiting when brought to the end of the queue, e.g. when waiting for data from the internet

    five-state model
        states
            - running
                currently being executed
            - ready
                in the queue, and can be run once the cpu is available
            - blocked
                waiting for external stimulus to execute, e.g. i/o or internet operations
            - new
                has been created, but has not yet been allocated to the queue
            - exit
                a pool of processes that have been released from the os and just need to terminate

        os perspective
            consider a, b, and c loaded in memory
            in addition, there is a small dispatcher that switches the processor from one process to another
                // round robin 6 instructions, meaning it changes every six instructions
            no use of virtual memory
            b invokes an i/o operation in its fourth memory

            execution time for this example
                [[diagram]]

        queueing discipline
            two queue now, ready and blocked
                - when the process is admitted in the system, it is placed in the queue
                - when a process is removed from the processor, it is either placed in ready or blocked
                - when an event occurs, all the processes that are waiting on that event are moved into the ready queue
                [[diagram]]
                [[diagram]]
                    -> multi-event queueing
                        when an event occurs, the entire waiting queue is moved to ready

        suspended processes
            [[diagram]]
            - processor is faster than i/o, so all processes may be waiting for i/o
            - swap these processes to disk to free up memmory
            - blocked becomes suspended when swapped to disk

        process management services
            create(&process_id, attributes)
                create a new process
            delete(process_id)
                finishes the process specified
                whenever it is terminated, all files are closed
                all allocated resources are released
            abort(process_id)
                delete for abnormal termination
                usually generates a "post-mortem dump" which contains the process state before termination
            suspend(process_id)
                suspends the specified process

process description
    // finish this at home

processes and threads
    a process is sometimes defined as a heavyweight process
    a thread is sometimes defined as a lightweight process

    used to separate two ideas
        process: the ownership of memory, files, other resources
        threads: unit of execution we use to dispatch
            -> each thread uses the same address space, hence it is much easier for them to communicate
            -> they use the process' address space
        
        multithreading
            allowing multiple threads per process
    thread
        a unit of computation associated with a particular heavyweight process, and uses many of that process' resources
        a process with one thread is a "classic" process
        a thread can belong to only one process

        threads have
            - individual execution states
            - each thread has their own control block with a state, saved registers, and a pointer
            - separate stack and hardware state per thread
            - 