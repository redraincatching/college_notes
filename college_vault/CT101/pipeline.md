# pipeline
pipelining is an implementation technique whereby multiple instructions are overlapped in an execution
- the goal of the pipeline is to reduce the execution time for a set of instructions
- key for most modern processors

each stage in the pipeline completes a part of the instruction
throughput is determined by how often an instruction exits the pipeline (i.e. gets completed)

## basic pipeline
![[basic_pipeline.png]]
we can pipeline the presented datapath with no changes by starting a new instruction on each clock cycle
![[basic_pipeline_1.png]]

the use of pipeline forces us to think about the following:
- datapaths should use separate instructions and data memories
the memory system should deliver five times the bandwidth
_// NOTE: bandwidth is maximum rate of data transfer across a given path_
- the register file is used in two stages: for reading in ID stage, and for writing in WB stage
this means we need to be able to do, at maximum, two reads and a write every clock cycle
_// what if a read and a write target the same register?_
- to start a new instruction every clock cycle, PC has to be incremented and stored every cycle, and this should be done in IF, during preparation for next instruction
the problem occurs when we consider the effect of taken branches, that change the PC as well, but not until the MEM stage
-> we'll deal with this by reorganising the way the PC gets written

pipelining the datapath requires that values passed from one pipe stage to the next be placed in registers. those registers, placed between each stage, are called pipeline registers
- they serve to convey data and control information from one stage to the next
- IF/ID, ID/EX, EX/MEM, MEM/WB
- PC can also be thought of as a pipeline register, that sits before the IF phase of an instruction, leading to one pipeline register for each stage

most of the data flows left to right, which is to say from earlier to later in time.
the paths that flow rtl, whcih carry the PC and values for the WB stage, introduce complications into our pipeline

![[basic_pipeline_2.png]]


#### pipelined instruction fetch
- IF/ID.IR <- mem\[PC\]
- IF/ID.NPC, PC <- If (EX/MEM.cond) {EX/MEM.ALUOutput}else{PC+4}
###### operation
send out the PC and fetch the instruction from memory
increment the PC by 4 to address the next instruction or save the address generated by a taken branch of a previous instruction in execution stage

#### pipelined instruction decode
        // TODO: finish this, also separate slides with the extra text


---
## performance issues with pipelining
### pipeline overhead
- increases the processor throughput
- does _not_ increase individual execution speed
-> actually decreases it a little, thanks to delay when writing to and reading from pipeline registers
-> however, the total program will have a lower total execution time
- physical limits on pipeline
->imbalance between stages, as the clock can only run as fast as the slowest stage (clock skew)

#### performance computation
consider our original example
- the ALU uses four cycles
- the relative freq. of ALU operations is 40%, and branches, 20%
- clock cycle is 10ns
- let the pipeline overhead be 1ns

average instruction execution time is, for the unpipelined example
clock cycle \* average CPI (cycles per instruction)
$= 10 ns * [(40\% + 20\%)*4 + 40\% * 5]$
$= 44ns$

// TODO: calculate that of pipelined example

---
## pipeline hazards
situations that prevent the next instruction in the stream from executing in its designated clock cycle
hazards reduce the performance from the ideal speedup gained by pipelining

three types:
- **structural hazards**
arise from resource conflicts when the hardware can't support all possible combinations of overlapping instructions
come from physical limitations, e.g. the limited number of registers
- **data hazards**
arise when an instruction depends on the results of a previous instruction in a way that is exposed by overlapping instructions in the pipeline
come from when instructions access the same registers
- **control hazards**
arise from the pipelining and branches and other instructions that change the PC

### stall
hazards in the pipeline can cause a stall
forcing an instruction to take more clock cycles than necessary to complete
eliminating a hazard often requires that some instructions can proceed while others are delated

when an instruction is stalled, any instructions that come later are affected, while earlier instructions must continue
-> no new instructions can be fetched during a stall

#### structural hazards
if certain combinations of instructions can't be accommodated because of resource conflicts, then the machine has structural hazards

can be generated by
- a functional unit that is not fully pipelined
- resources not being duplicated enough to allow all combinations in the pipeline to execute
e.g.
a machine may only have one file write port, but under certain circumstances, the pipeline may want to perform two writes in one clock cycle

consider a von neumann architecture
![[structural_hazard_1.png]]
![[structural_hazard_2.png]]
a stall cycle is added, also known as the pipeline bubble
![[structural_hazard_3.png]]

a machine with structural hazards will have a higher cpi
-> a designer might still, however, allow them for cost or latency purposes

#### data hazards
occur when the pipeline changes the order of read/write accesses to operands, so that the order differs from those seen by sequentially executing instructions on an un-pipelined machine
take this sequence of instructions:
```gpr
ADD r1, r2, r3
SUB R4, R1, R5
AND r6, r1, r7
OR r8, r1, r9
XOR r10, r1, r11
```
![[data_hazards_1.png]]
the use of results from ADD cause a hazard because the register is not written to until after the other instructions have read from it
![[data_hazards_2.png]]
the hazards can be eliminated using a technique known as forwarding
_// ess. reading directly from the ALU, and not waiting until it is in the register_
![[data_hazards_3.png]]
store requires an operand during MEM and forwarding is shown here
-> the result of the load is forwarded from the output in MEM/WB to the memory input to be stored
-> in addition, the ALUOutput is forwarded to ALUInput for address calculation for both load and store

##### data hazard classifications
depending on the order of read and write access in the instructions, data hazards can fit into three categories

consider two instructions, i and j
- RAW (read after write)
j tries to read a source before i writes to it, and j incorrectly gets the old value
most common type
- WAW (write after write)
j writes to an operand, and then i overwrites it
present in pipelines with more than one writing stage
- WAR (write after read)
j tries to write to a destination before i reads it, and i incorrectly gets the new value

##### data hazards requiring stalls
consider the following sequence
```gpr
LW r1, 0(r2)
SUB r4, r1, r5
AND r6, r1, r7
OR r8, r1, r9
```

the problem here is that the load operation will not have data until the end of the MEM stage
![[data_hazards_4.png]]
the load can forward results to the AND and OR operations, but not to sub, as that would require forwarding results in negative time
![[data_hazards_5.png]]
the load interlock causes a stall to be inserted at clock cycle 4, which then allows forwarding

##### compiler scheduling for data hazards
![[data_hazards_6.png]]
consider A = B + C
- the add must be stalled to allow the load of C to complete
- the SW does not need to be delayed, due to forwarding

rather than just allow the pipeline to stall, the compiler can try to rearrange the code to avoid this
-> this technique is known as pipeline scheduling

consider
```gpr
A = B + C
D = E - F
```
solution
```gpr
LW rb, B
LW rc, C
LW re, E    ;to avoid the stall
ADD ra, rb, rc
LW rf, F
SW A, ra
SUB rd, re, rf
SW D, rD
```

#### control hazards
can cause a greater performance loss than that of data hazards
- when a branch is executed, it may or may not change the PC
-> the branch can either be taken, or robert frost

if instruction i is a taken branch, then the value of pc will not change until the end MEM stage of the pipeline
-> a simple method to deal with branches would be to simply stall a branch once it is detected, until we know whether it will be taken or not
![[control_hazards.png]]

a branch causes a three-cycle stall in our example pipeline
-> one cycle is a repeated IF, necessary if the branch is taken, redundant if not
-> two stall cycles
-> this is a massive decrease, and can be reduced if we are able to find out if the branch is taken or not earlier


> #computing_systems 